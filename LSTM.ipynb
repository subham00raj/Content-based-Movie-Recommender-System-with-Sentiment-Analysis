{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "r0JFNQ0e6_SV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd    # to load dataset\n",
        "import numpy as np     # for mathematic equation\n",
        "from nltk.corpus import stopwords   # to get collection of stopwords\n",
        "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
        "from tensorflow.keras.models import Sequential     # the model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
        "from tensorflow.keras.models import load_model   # load saved model\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz6X8ZqO7dtP",
        "outputId": "eedf7838-810c-4596-f06f-aa85e18460a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7zuZ-YS6_SW",
        "outputId": "2241e0fd-f5e2-45f4-84c9-cae4ae45f3df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  review sentiment\n",
            "0      One of the other reviewers has mentioned that ...  positive\n",
            "1      A wonderful little production. <br /><br />The...  positive\n",
            "2      I thought this was a wonderful way to spend ti...  positive\n",
            "3      Basically there's a family where a little boy ...  negative\n",
            "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "...                                                  ...       ...\n",
            "49995  I thought this movie did a down right good job...  positive\n",
            "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
            "49997  I am a Catholic taught in parochial elementary...  negative\n",
            "49998  I'm going to have to disagree with the previou...  negative\n",
            "49999  No one expects the Star Trek movies to be high...  negative\n",
            "\n",
            "[50000 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/IMDB Dataset.csv')\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1_Gjibo7v0U",
        "outputId": "642828cf-42e4-429f-a53e-0e541e388cec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AchSt59v6_SY"
      },
      "outputs": [],
      "source": [
        "english_stops = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5lwjEYV6_SY",
        "outputId": "8dd9ea74-ed57-4e57-dc00-a95c65f44837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reviews\n",
            "0        [one, reviewers, mentioned, watching, oz, epis...\n",
            "1        [a, wonderful, little, production, the, filmin...\n",
            "2        [i, thought, wonderful, way, spend, time, hot,...\n",
            "3        [basically, family, little, boy, jake, thinks,...\n",
            "4        [petter, mattei, love, time, money, visually, ...\n",
            "                               ...                        \n",
            "49995    [i, thought, movie, right, good, job, it, crea...\n",
            "49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n",
            "49997    [i, catholic, taught, parochial, elementary, s...\n",
            "49998    [i, going, disagree, previous, comment, side, ...\n",
            "49999    [no, one, expects, star, trek, movies, high, a...\n",
            "Name: review, Length: 50000, dtype: object \n",
            "\n",
            "Sentiment\n",
            "0        1\n",
            "1        1\n",
            "2        1\n",
            "3        0\n",
            "4        1\n",
            "        ..\n",
            "49995    1\n",
            "49996    0\n",
            "49997    0\n",
            "49998    0\n",
            "49999    0\n",
            "Name: sentiment, Length: 50000, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def load_dataset():\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/IMDB Dataset.csv')\n",
        "    x_data = df['review']       # Reviews/Input\n",
        "    y_data = df['sentiment']    # Sentiment/Output\n",
        "\n",
        "    # PRE-PROCESS REVIEW\n",
        "    x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
        "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
        "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\n",
        "    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n",
        "\n",
        "    # ENCODE SENTIMENT -> 0 & 1\n",
        "    y_data = y_data.replace('positive', 1)\n",
        "    y_data = y_data.replace('negative', 0)\n",
        "\n",
        "    return x_data, y_data\n",
        "\n",
        "x_data, y_data = load_dataset()\n",
        "\n",
        "print('Reviews')\n",
        "print(x_data, '\\n')\n",
        "print('Sentiment')\n",
        "print(y_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6URyaa26_SZ",
        "outputId": "f542b8e0-7bce-45cb-c448-8fa4f3b635c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Set\n",
            "2855     [you, hardly, know, year, later, mgm, put, nor...\n",
            "7542     [i, saw, movie, child, longing, see, survived,...\n",
            "32275    [i, watched, film, i, say, surprised, it, well...\n",
            "25980    [key, west, short, time, appointment, tv, fami...\n",
            "45700    [obviously, film, going, straight, dvd, i, exp...\n",
            "                               ...                        \n",
            "37563    [artimisia, late, last, night, at, first, i, t...\n",
            "17948    [julie, meg, tilly, goody, two, shoes, type, h...\n",
            "12230    [this, astonishingly, bad, action, film, i, sa...\n",
            "38811    [if, ever, watched, dukes, hazard, know, never...\n",
            "18209    [the, opening, sequence, alone, worth, cost, a...\n",
            "Name: review, Length: 40000, dtype: object \n",
            "\n",
            "94       [i, watched, series, curiosity, wanting, see, ...\n",
            "13765    [i, usually, really, like, lawrence, australia...\n",
            "48398    [this, one, worst, movies, i, ever, seen, it, ...\n",
            "8032     [scarlet, coat, bendict, arnold, betraying, co...\n",
            "18310    [what, terrible, sequel, the, reason, i, give,...\n",
            "                               ...                        \n",
            "27161    [i, loved, movie, actors, wonderful, suited, r...\n",
            "8399     [directed, samuel, fuller, also, wrote, screen...\n",
            "36374    [chances, are, charming, romantic, fantasy, wo...\n",
            "35939    [one, b, c, movie, producer, roger, corman, gr...\n",
            "521      [one, best, ensemble, acted, films, i, ever, s...\n",
            "Name: review, Length: 10000, dtype: object \n",
            "\n",
            "Test Set\n",
            "2855     0\n",
            "7542     1\n",
            "32275    1\n",
            "25980    1\n",
            "45700    0\n",
            "        ..\n",
            "37563    1\n",
            "17948    1\n",
            "12230    0\n",
            "38811    0\n",
            "18209    1\n",
            "Name: sentiment, Length: 40000, dtype: int64 \n",
            "\n",
            "94       0\n",
            "13765    0\n",
            "48398    0\n",
            "8032     1\n",
            "18310    0\n",
            "        ..\n",
            "27161    1\n",
            "8399     1\n",
            "36374    1\n",
            "35939    1\n",
            "521      1\n",
            "Name: sentiment, Length: 10000, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n",
        "\n",
        "print('Train Set')\n",
        "print(x_train, '\\n')\n",
        "print(x_test, '\\n')\n",
        "print('Test Set')\n",
        "print(y_train, '\\n')\n",
        "print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2hDhC6z26_SZ"
      },
      "outputs": [],
      "source": [
        "def get_max_length():\n",
        "    review_length = []\n",
        "    for review in x_train:\n",
        "        review_length.append(len(review))\n",
        "\n",
        "    return int(np.ceil(np.mean(review_length)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQp-nXIT6_Sa",
        "outputId": "290c90d8-fb68-446b-9f0e-9f664ccda0b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded X Train\n",
            " [[  95  934   47 ...    0    0    0]\n",
            " [   1  117    3 ...    0    0    0]\n",
            " [   1  196    4 ...    0    0    0]\n",
            " ...\n",
            " [   8 9148   18 ...    0    0    0]\n",
            " [  55   51  196 ...    0    0    0]\n",
            " [   2  518  618 ...    0    0    0]] \n",
            "\n",
            "Encoded X Test\n",
            " [[    1   196   110 ...     0     0     0]\n",
            " [    1   541    13 ...     0     0     0]\n",
            " [    8     5   156 ...     0     0     0]\n",
            " ...\n",
            " [ 3722  1713  1212 ...     0     0     0]\n",
            " [    5   379   873 ...   409     7 11710]\n",
            " [    5    46  3253 ...     0     0     0]] \n",
            "\n",
            "Maximum review length:  130\n"
          ]
        }
      ],
      "source": [
        "# ENCODE REVIEW\n",
        "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
        "token.fit_on_texts(x_train)\n",
        "x_train = token.texts_to_sequences(x_train)\n",
        "x_test = token.texts_to_sequences(x_test)\n",
        "\n",
        "max_length = get_max_length()\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
        "\n",
        "print('Encoded X Train\\n', x_train, '\\n')\n",
        "print('Encoded X Test\\n', x_test, '\\n')\n",
        "print('Maximum review length: ', max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mynwrrab6_Sb",
        "outputId": "bf64d505-4158-4918-b296-351db4043a4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 130, 32)           2956192   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                24832     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2981089 (11.37 MB)\n",
            "Trainable params: 2981089 (11.37 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# ARCHITECTURE\n",
        "EMBED_DIM = 32\n",
        "LSTM_OUT = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
        "model.add(LSTM(LSTM_OUT))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NdLnTKWZ6_Sb"
      },
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    'models/LSTM.h5',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmLqtmvm6_Sb",
        "outputId": "aa5b95e8-e387-49fb-961f-4d3d4a01d6af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.5086 - accuracy: 0.7135\n",
            "Epoch 1: accuracy improved from -inf to 0.71352, saving model to models/LSTM.h5\n",
            "313/313 [==============================] - 47s 137ms/step - loss: 0.5086 - accuracy: 0.7135\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - ETA: 0s - loss: 0.2268 - accuracy: 0.9184\n",
            "Epoch 2: accuracy improved from 0.71352 to 0.91838, saving model to models/LSTM.h5\n",
            "313/313 [==============================] - 24s 76ms/step - loss: 0.2268 - accuracy: 0.9184\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.1360 - accuracy: 0.9571\n",
            "Epoch 3: accuracy improved from 0.91838 to 0.95705, saving model to models/LSTM.h5\n",
            "313/313 [==============================] - 23s 74ms/step - loss: 0.1360 - accuracy: 0.9571\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0880 - accuracy: 0.9749\n",
            "Epoch 4: accuracy improved from 0.95705 to 0.97490, saving model to models/LSTM.h5\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.0880 - accuracy: 0.9749\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0624 - accuracy: 0.9834\n",
            "Epoch 5: accuracy improved from 0.97490 to 0.98340, saving model to models/LSTM.h5\n",
            "313/313 [==============================] - 10s 31ms/step - loss: 0.0624 - accuracy: 0.9834\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79c6b7936ec0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train, batch_size = 128, epochs = 5, callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hBah01Z6_Sc"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### Testing\n",
        "To evaluate the model, we need to predict the sentiment using our <b>x_test</b> data and comparing the predictions with <b>y_test</b> (expected output) data. Then, we calculate the accuracy of the model by dividing numbers of correct prediction with the total data. Resulted an accuracy of <b>86.63%</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y0tt0TN6_Sc",
        "outputId": "eab0f43b-cf8c-4648-e032-a50995e84104"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 1s 5ms/step\n",
            "Correct Prediction: 0\n",
            "Wrong Prediction: 10000\n",
            "Accuracy: 0.0\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(x_test, batch_size = 128)\n",
        "\n",
        "true = 0\n",
        "for i, y in enumerate(y_test):\n",
        "    if y == y_pred[i]:\n",
        "        true += 1\n",
        "\n",
        "print('Correct Prediction: {}'.format(true))\n",
        "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
        "print('Accuracy: {}'.format(true/len(y_pred)*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLN3O3O-6_Sc"
      },
      "source": [
        "---\n",
        "\n",
        "### Load Saved Model\n",
        "\n",
        "Load saved model and use it to predict a movie review statement's sentiment (positive or negative)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xkxrlbgS6_Sc"
      },
      "outputs": [],
      "source": [
        "loaded_model = load_model('models/LSTM.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZRhM0qp6_Sc"
      },
      "source": [
        "Receives a review as an input to be predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG82FIZa6_Sc",
        "outputId": "cf0700cb-baa1-42b3-efc0-47c4d8ae5a3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Movie Review: fantastic\n"
          ]
        }
      ],
      "source": [
        "review = str(input('Movie Review: '))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paR6u2f16_Sd"
      },
      "source": [
        "The input must be pre processed before it is passed to the model to be predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwiysYnq6_Sd",
        "outputId": "f7796680-87bd-4de7-883f-bfe42860b746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned:  fantastic\n",
            "Filtered:  ['fantastic']\n"
          ]
        }
      ],
      "source": [
        "# Pre-process input\n",
        "regex = re.compile(r'[^a-zA-Z\\s]')\n",
        "review = regex.sub('', review)\n",
        "print('Cleaned: ', review)\n",
        "\n",
        "words = review.split(' ')\n",
        "filtered = [w for w in words if w not in english_stops]\n",
        "filtered = ' '.join(filtered)\n",
        "filtered = [filtered.lower()]\n",
        "\n",
        "print('Filtered: ', filtered)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABP_IRB_6_Sd"
      },
      "source": [
        "Once again, we need to tokenize and encode the words. I use the tokenizer which was previously declared because we want to encode the words based on words that are known by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxVzqqNs6_Sd",
        "outputId": "e2d5eb66-fb5f-4661-87ca-255f529d3850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[695   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0]]\n"
          ]
        }
      ],
      "source": [
        "tokenize_words = token.texts_to_sequences(filtered)\n",
        "tokenize_words = pad_sequences(tokenize_words, maxlen=max_length, padding='post', truncating='post')\n",
        "print(tokenize_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR0ov96d6_Sd"
      },
      "source": [
        "This is the result of the prediction which shows the **confidence score** of the review statement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HRmlYIs6_Sd",
        "outputId": "9585621d-1896-497a-9c42-2ac64dfd85a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 501ms/step\n",
            "[[0.9956091]]\n"
          ]
        }
      ],
      "source": [
        "result = loaded_model.predict(tokenize_words)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g64pnBYv6_Se"
      },
      "source": [
        "If the confidence score is close to 0, then the statement is **negative**. On the other hand, if the confidence score is close to 1, then the statement is **positive**. I use a threshold of **0.7** to determine which confidence score is positive and negative, so if it is equal or greater than 0.7, it is **positive** and if it is less than 0.7, it is **negative**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP67DH_G6_Se",
        "outputId": "58bdf60b-1e91-4bda-fd8d-cb81cfa4f903"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "positive\n"
          ]
        }
      ],
      "source": [
        "if result >= 0.7:\n",
        "    print('positive')\n",
        "else:\n",
        "    print('negative')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
